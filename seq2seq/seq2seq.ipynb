{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd60cd27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:41:03.592689Z",
     "iopub.status.busy": "2025-06-10T09:41:03.592309Z",
     "iopub.status.idle": "2025-06-10T09:41:06.017987Z",
     "shell.execute_reply": "2025-06-10T09:41:06.016618Z"
    },
    "papermill": {
     "duration": 2.434207,
     "end_time": "2025-06-10T09:41:06.020677",
     "exception": false,
     "start_time": "2025-06-10T09:41:03.586470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934fcf60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:41:06.030065Z",
     "iopub.status.busy": "2025-06-10T09:41:06.029596Z",
     "iopub.status.idle": "2025-06-10T09:41:06.064485Z",
     "shell.execute_reply": "2025-06-10T09:41:06.063498Z"
    },
    "papermill": {
     "duration": 0.04147,
     "end_time": "2025-06-10T09:41:06.066222",
     "exception": false,
     "start_time": "2025-06-10T09:41:06.024752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/data-seq2seq-real/data.tsv', sep='\\t', header=None, names=['input', 'target'])\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55182c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:41:06.074583Z",
     "iopub.status.busy": "2025-06-10T09:41:06.074283Z",
     "iopub.status.idle": "2025-06-10T09:41:06.100777Z",
     "shell.execute_reply": "2025-06-10T09:41:06.099633Z"
    },
    "papermill": {
     "duration": 0.032726,
     "end_time": "2025-06-10T09:41:06.102518",
     "exception": false,
     "start_time": "2025-06-10T09:41:06.069792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello you</td>\n",
       "      <td>Hello, how are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meet you nice</td>\n",
       "      <td>Nice to meet you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sit please</td>\n",
       "      <td>Please sit down.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes please</td>\n",
       "      <td>Yes, please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you meet nice</td>\n",
       "      <td>Nice to meet you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>please sit you</td>\n",
       "      <td>Please sit down.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hello</td>\n",
       "      <td>Hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nice meet you</td>\n",
       "      <td>Nice to meet you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you nice meet</td>\n",
       "      <td>Nice to meet you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hello name you</td>\n",
       "      <td>Hello, what's your name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>you yes</td>\n",
       "      <td>Yes, you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T O M</td>\n",
       "      <td>My name is TOM.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>name T O M</td>\n",
       "      <td>My name is TOM.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hello T O M</td>\n",
       "      <td>Hello, TOM!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>meet T O M</td>\n",
       "      <td>Nice to meet you, TOM.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hello</td>\n",
       "      <td>Hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>meet</td>\n",
       "      <td>Let's meet!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>name</td>\n",
       "      <td>What's your name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nice</td>\n",
       "      <td>That's nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>please</td>\n",
       "      <td>Please!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sit</td>\n",
       "      <td>Sit down, please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yes</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>you</td>\n",
       "      <td>You!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             input                    target\n",
       "1        hello you       Hello, how are you?\n",
       "2    meet you nice         Nice to meet you.\n",
       "3       sit please          Please sit down.\n",
       "4       yes please              Yes, please.\n",
       "5    you meet nice         Nice to meet you.\n",
       "6   please sit you          Please sit down.\n",
       "7            hello                    Hello!\n",
       "8    nice meet you         Nice to meet you.\n",
       "9    you nice meet         Nice to meet you.\n",
       "10  hello name you  Hello, what's your name?\n",
       "11         you yes                 Yes, you.\n",
       "12           T O M           My name is TOM.\n",
       "13      name T O M           My name is TOM.\n",
       "14     hello T O M               Hello, TOM!\n",
       "15      meet T O M    Nice to meet you, TOM.\n",
       "16           hello                    Hello!\n",
       "17            meet               Let's meet!\n",
       "18            name         What's your name?\n",
       "19            nice              That's nice.\n",
       "20          please                   Please!\n",
       "21             sit         Sit down, please.\n",
       "22             yes                      Yes.\n",
       "23             you                      You!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a4891b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:41:06.111584Z",
     "iopub.status.busy": "2025-06-10T09:41:06.111247Z",
     "iopub.status.idle": "2025-06-10T09:41:06.116414Z",
     "shell.execute_reply": "2025-06-10T09:41:06.115375Z"
    },
    "papermill": {
     "duration": 0.011614,
     "end_time": "2025-06-10T09:41:06.118012",
     "exception": false,
     "start_time": "2025-06-10T09:41:06.106398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.lower().strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc5923d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:41:06.127627Z",
     "iopub.status.busy": "2025-06-10T09:41:06.127330Z",
     "iopub.status.idle": "2025-06-10T09:41:06.142487Z",
     "shell.execute_reply": "2025-06-10T09:41:06.141199Z"
    },
    "papermill": {
     "duration": 0.022306,
     "end_time": "2025-06-10T09:41:06.144152",
     "exception": false,
     "start_time": "2025-06-10T09:41:06.121846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG VOCAB CREATION ---\n",
      "target_vocab (len 34): ['<PAD>', '<SOS>', '<EOS>', 'sit', \"that's\", 'tom!', 'to', 'you,', 'meet', 'down.', 'you!', 'please!', \"let's\", 'name?', 'my', 'how', 'you.', 'down,', 'please.', 'hello,', 'nice', 'tom.', \"what's\", 'yes,', 'is', 'your', 'name', 'you?', 'yes.', 'are', 'meet!', 'nice.', 'please', 'hello!']\n",
      "target_word2idx['<EOS>']: 2\n",
      "target_idx2word[2]: <EOS>\n",
      "Keys in target_idx2word (first 10 of 34): [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "--- END DEBUG VOCAB CREATION ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_input_words = []\n",
    "all_target_words = []\n",
    "for idx,row in data.iterrows():\n",
    "    all_input_words.extend(tokenize(row['input']))\n",
    "    all_target_words.extend(tokenize(row['target'])) # Đảm bảo đây là row['target']\n",
    "PAD_TOKEN = '<PAD>'\n",
    "SOS_TOKEN = '<SOS>'\n",
    "EOS_TOKEN = '<EOS>'\n",
    "\n",
    "input_vocab = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN] + list(set(all_input_words))\n",
    "\n",
    "target_vocab = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN] + list(set(all_target_words))\n",
    "\n",
    "input_word2idx = {word : idx for idx,word in enumerate(input_vocab)}\n",
    "input_idx2word = {idx : word for idx,word in input_word2idx.items()} # Cách này đúng\n",
    "\n",
    "target_word2idx = {word : idx for idx,word in enumerate(target_vocab)}\n",
    "target_idx2word = {idx : word for idx,word in enumerate(target_vocab)} # Cách xây dựng trực tiếp target_idx2word từ target_vocab\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- DEBUG VOCAB CREATION ---\")\n",
    "print(f\"target_vocab (len {len(target_vocab)}): {target_vocab}\")\n",
    "print(f\"target_word2idx['<EOS>']: {target_word2idx.get('<EOS>')}\")\n",
    "eos_idx = target_word2idx.get('<EOS>')\n",
    "if eos_idx is not None:\n",
    "    print(f\"target_idx2word[{eos_idx}]: {target_idx2word.get(eos_idx)}\")\n",
    "print(f\"Keys in target_idx2word (first 10 of {len(target_idx2word)}): {sorted(list(target_idx2word.keys()))[:10]}\")\n",
    "print(\"--- END DEBUG VOCAB CREATION ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9646459b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:41:06.154114Z",
     "iopub.status.busy": "2025-06-10T09:41:06.153726Z",
     "iopub.status.idle": "2025-06-10T09:41:06.158950Z",
     "shell.execute_reply": "2025-06-10T09:41:06.157982Z"
    },
    "papermill": {
     "duration": 0.01201,
     "end_time": "2025-06-10T09:41:06.160557",
     "exception": false,
     "start_time": "2025-06-10T09:41:06.148547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_input(text):\n",
    "    return [input_word2idx[word] for word in tokenize(text)]\n",
    "def encode_target(text):\n",
    "    return [target_word2idx[SOS_TOKEN]] + [target_word2idx[word] for word in tokenize(text)] + [target_word2idx[EOS_TOKEN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611a80b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:41:06.169175Z",
     "iopub.status.busy": "2025-06-10T09:41:06.168840Z",
     "iopub.status.idle": "2025-06-10T09:41:06.270552Z",
     "shell.execute_reply": "2025-06-10T09:41:06.269122Z"
    },
    "papermill": {
     "duration": 0.107892,
     "end_time": "2025-06-10T09:41:06.272216",
     "exception": true,
     "start_time": "2025-06-10T09:41:06.164324",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1291735257.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSeq2SeqDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df['input'].apply(encode_input).tolist()\n",
    "        self.targets = df['target'].apply(encode_target).tolist()\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "        \n",
    "dataset = Seq2SeqDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fefef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:38:51.959920Z",
     "iopub.status.busy": "2025-06-10T09:38:51.959108Z",
     "iopub.status.idle": "2025-06-10T09:38:51.968302Z",
     "shell.execute_reply": "2025-06-10T09:38:51.967072Z",
     "shell.execute_reply.started": "2025-06-10T09:38:51.959894Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    \n",
    "    input_lens = [len(seq) for seq in inputs]\n",
    "    target_lens = [len(seq) for seq in targets]\n",
    "    \n",
    "    max_input_len = max(input_lens)\n",
    "    max_target_len = max(target_lens)\n",
    "    \n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "    \n",
    "    for seq in inputs:\n",
    "        padded_seq = seq + [input_word2idx[PAD_TOKEN]] * (max_input_len - len(seq))\n",
    "        padded_inputs.append(padded_seq)\n",
    "        \n",
    "    for seq in targets:\n",
    "        padded_seq = seq + [target_word2idx[PAD_TOKEN]] * (max_target_len - len(seq))\n",
    "        padded_targets.append(padded_seq)\n",
    "        \n",
    "    return torch.tensor(padded_inputs), torch.tensor(input_lens), torch.tensor(padded_targets), torch.tensor(target_lens)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0766c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:39:01.619699Z",
     "iopub.status.busy": "2025-06-10T09:39:01.619242Z",
     "iopub.status.idle": "2025-06-10T09:39:01.627043Z",
     "shell.execute_reply": "2025-06-10T09:39:01.625718Z",
     "shell.execute_reply.started": "2025-06-10T09:39:01.619673Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, embed_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        outputs, hidden = self.gru(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24b880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:39:11.947206Z",
     "iopub.status.busy": "2025-06-10T09:39:11.946845Z",
     "iopub.status.idle": "2025-06-10T09:39:11.954521Z",
     "shell.execute_reply": "2025-06-10T09:39:11.953374Z",
     "shell.execute_reply.started": "2025-06-10T09:39:11.947183Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, target_vocab_size, embed_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(target_vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, target_vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = x.unsqueeze(1)  # batch_size x 1\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        prediction = self.fc(output.squeeze(1))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c34bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:39:23.187229Z",
     "iopub.status.busy": "2025-06-10T09:39:23.186362Z",
     "iopub.status.idle": "2025-06-10T09:39:23.196450Z",
     "shell.execute_reply": "2025-06-10T09:39:23.195208Z",
     "shell.execute_reply.started": "2025-06-10T09:39:23.187197Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(encoder, decoder, dataloader, encoder_optimizer, decoder_optimizer, criterion, device):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, input_lens, targets, target_lens in dataloader:\n",
    "        inputs, input_lens = inputs.to(device), input_lens.to(device)\n",
    "        targets, target_lens = targets.to(device), target_lens.to(device)\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_outputs, hidden = encoder(inputs, input_lens)\n",
    "        \n",
    "        batch_size = inputs.size(0)\n",
    "        max_target_len = targets.size(1)\n",
    "        \n",
    "        # decoder input start with <SOS>\n",
    "        decoder_input = targets[:, 0]  \n",
    "        decoder_hidden = hidden\n",
    "        \n",
    "        loss = 0\n",
    "        # Teacher forcing ratio\n",
    "        teacher_forcing_ratio = 0.5\n",
    "        \n",
    "        for t in range(1, max_target_len):\n",
    "            output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(output, targets[:, t])\n",
    "            \n",
    "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            decoder_input = targets[:, t] if teacher_force else top1\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() / max_target_len\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb62ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:39:37.502273Z",
     "iopub.status.busy": "2025-06-10T09:39:37.501865Z",
     "iopub.status.idle": "2025-06-10T09:39:37.517075Z",
     "shell.execute_reply": "2025-06-10T09:39:37.515810Z",
     "shell.execute_reply.started": "2025-06-10T09:39:37.502244Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_word2idx, target_word2idx, target_idx2word, encode_input_func, max_len=20, device='cpu'): # đổi tên encode_input để tránh nhầm lẫn\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # Sử dụng hàm encode_input_func được truyền vào\n",
    "    tokens = encode_input_func(sentence) # Đổi tên ở đây nếu cần\n",
    "    print(f\"Input sentence: '{sentence}'\")\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(f\"Input vocab size for check: {len(input_word2idx)}\")\n",
    "\n",
    "\n",
    "    inputs = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    lengths = torch.tensor([len(tokens)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = encoder(inputs, lengths)\n",
    "        decoder_input = torch.tensor([target_word2idx['<SOS>']]).to(device)\n",
    "        decoder_hidden = hidden\n",
    "\n",
    "        decoded_words = []\n",
    " \n",
    "\n",
    "        for i in range(max_len):\n",
    "            output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            top1 = output.argmax(1).item()\n",
    "   \n",
    "\n",
    "            if top1 not in target_idx2word:\n",
    "                print(f\"----> CRITICAL: Index {top1} is NOT a key in target_idx2word (max index is {len(target_idx2word)-1})\")\n",
    "            \n",
    "            if top1 == target_word2idx['<EOS>']:\n",
    "                print(\"Predicted EOS token.\")\n",
    "                break\n",
    "\n",
    "            word = target_idx2word.get(top1, '<UNK>') # Default to <UNK>\n",
    "            if word == '<UNK>':\n",
    "                print(f\"----> WARNING: Predicted token is <UNK> for index {top1}\")\n",
    "            decoded_words.append(word)\n",
    "\n",
    "            decoder_input = torch.tensor([top1]).to(device)\n",
    "    \n",
    "    return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb7d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:39:48.298228Z",
     "iopub.status.busy": "2025-06-10T09:39:48.297933Z",
     "iopub.status.idle": "2025-06-10T09:39:53.082107Z",
     "shell.execute_reply": "2025-06-10T09:39:53.080843Z",
     "shell.execute_reply.started": "2025-06-10T09:39:48.298209Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "\n",
    "encoder = Encoder(len(input_vocab), embed_size, hidden_size).to(device)\n",
    "decoder = Decoder(len(target_vocab), embed_size, hidden_size).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=target_word2idx[PAD_TOKEN])\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(encoder, decoder, dataloader, encoder_optimizer, decoder_optimizer, criterion, device)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95feafbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T09:40:27.487182Z",
     "iopub.status.busy": "2025-06-10T09:40:27.486875Z",
     "iopub.status.idle": "2025-06-10T09:40:27.500767Z",
     "shell.execute_reply": "2025-06-10T09:40:27.499716Z",
     "shell.execute_reply.started": "2025-06-10T09:40:27.487163Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_input_for_eval(sentence):\n",
    "    return [input_word2idx.get(word, input_word2idx['<PAD>']) for word in sentence.lower().split()]\n",
    "\n",
    "predicted_sentence = evaluate(encoder, decoder, \" name T O M\", input_word2idx, target_word2idx, target_idx2word, encode_input_for_eval, device=device)\n",
    "print(predicted_sentence)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7596177,
     "sourceId": 12068157,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7596294,
     "sourceId": 12068311,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7596492,
     "sourceId": 12068609,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7629772,
     "sourceId": 12117630,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.782067,
   "end_time": "2025-06-10T09:41:06.897315",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-10T09:40:58.115248",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
